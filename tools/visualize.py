# tools/visualize.py
"""
åŠŸèƒ½ï¼š
- éå†æŒ‡å®šç›®å½•ä¸‹çš„ *_recon.npy å’Œ *_gt.npy æ–‡ä»¶
- å¯¹æ¯”æ¯ä¸ªæ ·æœ¬çš„é‡å»ºç‚¹äº‘å’ŒçœŸå®ç‚¹äº‘
- ä»…ä¿å­˜åŠ¨æ€æ—‹è½¬å›¾ï¼ˆ.gifï¼‰ï¼Œå¹¶åœ¨æ ‡é¢˜ä¸­æ ‡æ³¨ Chamfer Distance
- ç»Ÿè®¡æ‰€æœ‰æ ·æœ¬çš„ Chamfer Distanceï¼Œè®¡ç®—å‡å€¼ä¸æ–¹å·®ï¼Œå¹¶å†™å…¥ outs/<save_dir>/cd.json

è¾“å‡ºè·¯å¾„ï¼šouts/vis_compare/<timestamp>/
"""

import os
import argparse
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # noqa: F401
from matplotlib import animation
import random
import json  # NEW: ç”¨äºå†™ cd.json


# ========== Chamfer Distance ==========
def chamfer_distance_numpy(x: np.ndarray, y: np.ndarray) -> float:
    """
    ä½¿ç”¨ NumPy å®ç°å¯¹ç§° Chamfer è·ç¦»
    å‚æ•°:
        x: [M, 3] numpy array
        y: [N, 3] numpy array
    è¿”å›:
        float: chamfer distance
    """
    x = x[:, np.newaxis, :]  # [M, 1, 3]
    y = y[np.newaxis, :, :]  # [1, N, 3]
    dist = np.sum((x - y) ** 2, axis=2)  # [M, N]
    cd = np.mean(np.min(dist, axis=1)) + np.mean(np.min(dist, axis=0))
    return float(cd)


# ========== åŠ¨å›¾ç”Ÿæˆå‡½æ•° ==========
def save_rotation_gif(points, filename, title):
    """
    ä¿å­˜ç‚¹äº‘ä¸ºæ—‹è½¬è§†è§’çš„ gif å›¾ã€‚
    """
    fig = plt.figure(figsize=(4, 4))
    ax = fig.add_subplot(111, projection='3d')
    scat = ax.scatter(points[:, 0], points[:, 1], points[:, 2], s=1)
    ax.set_axis_off()
    ax.set_title(title)

    def rotate(i):
        ax.view_init(elev=20, azim=i)
        return scat,

    anim = animation.FuncAnimation(fig, rotate, frames=np.arange(0, 360, 4), interval=40)
    anim.save(filename, writer='pillow', dpi=150)
    plt.close(fig)


# ========== ä¸»å‡½æ•°ï¼šå¯¹æ¯”é‡å»ºå’ŒGT ==========
def visualize_recon_vs_gt(npy_dir, out_dir="outs/vis_compare", max_batches=10):
    """
    éå†æŒ‡å®šç›®å½•ä¸‹çš„ *_recon.npy å’Œ *_gt.npy æ–‡ä»¶ï¼Œå¯¹æ¯”é‡å»ºå’ŒGTã€‚
    å‚æ•°:
        npy_dir: ä¿å­˜ .npy æ–‡ä»¶çš„ç›®å½•
        out_dir: ä¿å­˜å¯è§†åŒ–å›¾åƒçš„ç›®å½•ï¼ˆæœ€ç»ˆä¼šåœ¨å…¶ä¸‹å†åˆ›å»º <timestamp>/ï¼‰
        max_batches: æœ€å¤šå¯è§†åŒ–çš„ batch æ•°é‡ï¼›-1 è¡¨ç¤ºå…¨éƒ¨
    """
    os.makedirs(out_dir, exist_ok=True)

    files = sorted(f for f in os.listdir(npy_dir) if f.endswith("_recon.npy"))

    random.seed(20040303)
    random.shuffle(files)

    if max_batches != -1:
        files = files[:max_batches]

    # NEW: æ”¶é›†æ‰€æœ‰æ ·æœ¬çš„ CDï¼Œåšç»Ÿè®¡å¹¶å†™å…¥ JSON
    all_cd_values = []
    cd_records = []  # æ¯ä¸ªæ ·æœ¬çš„è¯¦ç»†è®°å½•ï¼ˆæ–‡ä»¶åã€idxã€CDï¼‰

    for f in files:
        batch_id = f[:5]
        recon_path = os.path.join(npy_dir, f)
        gt_path = os.path.join(npy_dir, f"{batch_id}_gt.npy")

        if not os.path.exists(gt_path):
            print(f"âš ï¸ Missing GT for {f}, skipping...")
            continue

        recon = np.load(recon_path)  # [B, N, 3] æˆ– [N, 3]
        gt = np.load(gt_path)        # [B, N, 3] æˆ– [N, 3]

        # å¦‚æœåªæœ‰ä¸¤ç»´ï¼Œè‡ªåŠ¨åŠ  batch ç»´
        if recon.ndim == 2 and recon.shape[1] == 3:
            recon = recon[None, ...]   # -> [1, N, 3]
        if gt.ndim == 2 and gt.shape[1] == 3:
            gt = gt[None, ...]         # -> [1, N, 3]

        B = recon.shape[0]
        for i in range(B):
            cd = chamfer_distance_numpy(recon[i], gt[i])

            # è®°å½•åˆ°åˆ—è¡¨ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
            all_cd_values.append(cd)
            cd_records.append({
                "batch_id": batch_id,
                "index_in_batch": i,
                "recon_file": f,
                "gt_file": f"{batch_id}_gt.npy",
                "cd": cd
            })

            # ä¿å­˜ GIFï¼šé‡å»º & GT
            recon_gif_path = os.path.join(out_dir, f"{batch_id}_{i:03d}_recon.gif")
            gt_gif_path    = os.path.join(out_dir, f"{batch_id}_{i:03d}_gt.gif")

            save_rotation_gif(recon[i], recon_gif_path, title=f"Reconstruction\nCD = {cd:.6f}")
            save_rotation_gif(gt[i],    gt_gif_path,    title="Ground Truth")

            print(f"âœ… Saved: {recon_gif_path}, {gt_gif_path}")

    # NEW: ç»Ÿè®¡ä¸å†™æ–‡ä»¶ï¼ˆä»…å½“æœ‰æ ·æœ¬æ—¶ï¼‰
    if len(all_cd_values) > 0:
        cd_array = np.asarray(all_cd_values, dtype=np.float64)
        cd_mean = float(np.mean(cd_array))
        cd_var  = float(np.var(cd_array, ddof=0))  # æ€»ä½“æ–¹å·®ï¼›éœ€è¦æ ·æœ¬æ–¹å·®å¯ç”¨ ddof=1

        summary = {
            "count": int(cd_array.size),
            "mean": cd_mean,
            "var": cd_var,
            "values": all_cd_values,
            "records": cd_records
        }

        # å°†ç»Ÿè®¡å†™å…¥ outs/<save_dir>/cd.jsonï¼›æ­¤å¤„ <save_dir> å°±æ˜¯ out_dir
        json_path = os.path.join(out_dir, "cd.json")
        with open(json_path, "w", encoding="utf-8") as fjson:
            json.dump(summary, fjson, ensure_ascii=False, indent=2)
        print(f"ğŸ“ CD stats saved to: {json_path}")
    else:
        print("âš ï¸ No valid pairs found. Nothing to summarize.")


# ========== å‘½ä»¤è¡Œå…¥å£ ==========
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="å¯è§†åŒ– Shape é‡å»ºç»“æœä¸ GT å¯¹æ¯”å›¾åƒ")
    parser.add_argument("timestamp", type=str, help="æŒ‡å®šé‡å»ºç»“æœçš„æ—¶é—´æˆ³å­ç›®å½•")
    parser.add_argument("--max_batches", type=int, default=10, help="æœ€å¤šå¯è§†åŒ–çš„ batch æ•°é‡ï¼Œ-1 è¡¨ç¤ºå…¨éƒ¨")
    args = parser.parse_args()

    input_dir = os.path.join("outs/reconstruct", args.timestamp)
    output_dir = os.path.join("outs/vis_compare", args.timestamp)
    os.makedirs(output_dir, exist_ok=True)  # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    visualize_recon_vs_gt(npy_dir=input_dir, out_dir=output_dir, max_batches=args.max_batches)
